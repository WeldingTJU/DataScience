# RoBERTaâ€‘Base Abstract Binaryâ€‘Classification Model  
*Fineâ€‘tuned **robertaâ€‘base** with [Simple Transformers](https://simpletransformers.ai/)*

---

## ğŸ“¦ Repository Contents

| File | Description |
|------|-------------|
| `config.json` | ğŸ¤—Â Transformers model configuration |
| `model.safetensors` | **â‰ˆâ€¯487â€¯MB** fineâ€‘tuned weights |
| `model_args.json` | SimpleÂ Transformers training arguments |
| `training_args.bin` | HuggingFace `TrainingArguments` snapshot |
| `tokenizer.json`, `vocab.json` | Tokenizer and vocabulary |
| `special_tokens_map.json` | Extra specialâ€‘tokens mapping |
| `tokenizer_config.json`, `merges.txt` | Tokenizer settings & BPE merges |
| `README.md` | This instruction |

---

## ğŸ§© Model Overview

The model is a **robertaâ€‘base** checkpoint fineâ€‘tuned on ~500 research abstracts for a **binary textâ€‘classification** task:  
detecting whether an abstract relates to **weldingâ€‘fatigue** research.

| Label | Meaning |
|-------|---------|
| `1`   | *weldâ€‘fatigue* abstract |
| `0`   | nonâ€‘weldâ€‘fatigue abstract |

---

## ğŸš€ QuickÂ Start

### 1. Install dependencies

```bash
pip install simpletransformers==0.64.3
# SimpleÂ Transformers will pull in transformers, torch, scikitâ€‘learn, pandas â€¦
```

### 2. Inference example

```python
from simpletransformers.classification import ClassificationModel

# local model directory
model_dir = r"PATH/TO/class_abstract"    # â† replace with your path
model = ClassificationModel("roberta", model_dir, use_cuda=False)

texts = [
    "(1) Numerical simulation method of Ultrasonic Pulse-Echo Inspection, which potentially Is a powerful means for Non Destructive Evaluation of cracks and flaws of steel structures, is built â€¦â€¦ "
    "316l(n) stainless steel plates were joined using activated-tungsten inert gas (a-tig) welding and conventional tig welding process â€¦â€¦ ",
]

preds, logits = model.predict(texts)
print("Predicted labels:", preds)   # e.g. [1, 0]
```
